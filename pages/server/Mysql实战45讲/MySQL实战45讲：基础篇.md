# MySQL实战45讲：基础篇

## 一.SQL查询语句的执行

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/0d2070e8f84c4801adbfa03bda1f98d9.png)

#### 连接器

连接器这一层，默认会有**长连接**。长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。

长连接可以减少建连的过程，提升数据库性能，但是会导致**MySQL占用内存涨的特别快**，这是因为执行过程中临时使用的内存是管理在连接对象里面的。最终MySQL会OOM，看起来就像是异常重启了。

#### 查询缓存

查询缓存是将之前运行过的语句及结果以kv形式缓存在内存中。能被缓存的语句必须有几个限制：

- 查询语句中含有不确定的值时，不会缓存
- 查询mysql, information_schema或performance_schema数据库中的表时，不会走查询缓存。
- 在存储的函数，触发器或事件的主体内执行的查询。
- 如果表更改，则使用该表的所有高速缓存查询都变为无效并从缓存中删除。这一条很关键。

查询缓存适用于高成本读远多于写，很长时间才会更新一次的情况。

查询缓存有几个致命的缺点：

- 在多核机器上扩展性不好。
- 严重影响性能预测性（predictability of performance）。

所以mysql 8.0以后移除了查询缓存的支持。[官网](https://dev.mysql.com/blog-archive/mysql-8-0-retiring-support-for-the-query-cache/)

#### 执行器

执行器开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误。如果有权限，就打开表继续执行，打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口。

执行器的执行流程是这样的：

- 调用 InnoDB 引擎接口取这个表的第一行，判断是否符合条件，如果不是则跳过，如果是则将这行存在结果集中；
- 调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。
- 执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端。

所以执行器负责调用引擎定义好的接口，不同引擎实现相同接口就行。面向接口编程~

我们会在数据库的慢查询日志中看到一个 `rows_examined`的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 `rows_examined`并不是完全相同的。

## 二.日志系统：一条SQL更新语句是怎样执行的

MySQL通过WAL(Write-Ahead Logging)技术来保障数据的稳定和可恢复。WAL的关键点就是先写日志，再写磁盘。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/1460000023827701.png)

#### redo log

redo log记录的是事务对数据页做了哪些修改，而不是完整的修改后的数据。这样记录的数据更少，而且可以顺序IO。

系统崩溃以后，可以通过redo log恢复到之前的状态。

`redo log `包括两部分：一个是内存中的日志缓冲( `redo log buffer `)，另一个是磁盘上的日志文件( `redo log file`)。mysql每执行一条 `DML `语句，先将记录写入 `redo log buffer `，后续某个时间点再一次性将多个操作记录写到 `redo log file `。

`mysql `支持三种将 `redo log buffer `写入 `redo log file `的时机，可以通过 `innodb_flush_log_at_trx_commit` 参数配置，各参数值含义如下：

- 0（延迟写）：事务提交时不会将 `redo log buffer `中日志写入到 `os buffer `，而是每秒写入 `os buffer `并调用 `fsync() `写入到 `redo log file `中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。
- 1（实时写，实时刷）：事务每次提交都会将 `redo log buffer `中的日志写入 `os buffer `并调用 `fsync() `刷到 `redo log file `中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。
- 2（实时写，延迟刷）：每次提交都仅写入到 `os buffer `，然后是每秒调用 `fsync() `将 `os buffer `中的日志写入到 `redo log file `。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/1460000023827700.png)

redo log实际上记录数据页的变更，而这种变更记录没必要全部保存，因此redo log实现上采用了大小固定、循环写入的方式，当写到结尾时，会回到开头循环写日志。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/1460000023827699.png)

#### undo log

数据库事务四大特性中有一个是 **原子性** ，具体来说就是 **原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况**。原子性底层就是依赖于undo log。

前面我们说到redo log记录的是每个事务对数据页操作的物理层面的变更，但是redo log其实是不能回溯的，所以事务如果失败了要回滚的话，不能依赖于redo log。所以innodb了undo log。

- **Redo Log** 记录了此次事务 **「完成后」** 的数据状态，记录的是更新之 **「后」** 的值。就像在命令行敲了很长的命令，敲回车执行，结果报错了。这时候只要按一个↑就能拿到上一条命令，再执行一遍即可。
- **Undo Log** 记录了此次事务 **「开始前」** 的数据状态，记录的是更新之 **「前」** 的值。类似于git reset --hard $lastCommitId。

在更新Buffer Pool中的数据之前，我们需要先将该数据事务开始之前的状态写入undo log中，假设更新到一半失败了，我们就可以通过undo log来回滚到事务开始前。

![MySQL 崩溃恢复](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/1460000039180239.jpeg)

写入了undo log之后，修改buffer pool中的数据时，mysql会将undolog日志的地址复制给每一行记录中的 `roll_pointer`字段。

![mvcc3](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/ccde9c179fae491484bfffb3d8e4f521~tplv-k3u1fbpfcp-zoom-in-crop-mark:1304:0:0:0.awebp)

#### binlog

MySQL 整体来看，其实就有两块：一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。上面我们聊到的 `redo log` 是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 `binlog`（归档日志）。

系统给 binlog 分配了一片内存作为 binlog cache，每个线程一个，参数 binlog_cache_size 用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。事务提交的时候，执行器把 binlog cache 里的完整事务写入到 binlog 中，并清空 binlog cache。

binlog与redolog的区别：

- redo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用
- redo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID=2 这一行的 c 字段加 1 ”。
- redo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。

下面是一条更新指令的执行流程。浅色框表示是在 InnoDB 内部执行的，深色框表示是在执行器中执行的。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/2e5bff4910ec189fe1ee6e2ecc7b4bbe.png)

这里采用了**两阶段提交**的方法，把redolog的状态分为了prepare和commit，主要是为了让redolog和binlog之间的逻辑一致。

> Q：为什么需要两阶段提交？为什么不能先写redo log，再写binlog，最后崩溃恢复的时候看两条是否都完整来判断是否成功？
>
> 主要的原因是因为 redo log提交就是事务提交的标识。如果事务提交后，数据能够被回滚，那期间新的事务对该被回滚数据的数据更新变回丢失，这是不能接受的。 当先写redo log后直接提交，再写binlog时，如果binlog写入失败，而redo log又已经提交无法回滚了，则binlog与数据产生不一致问题。
>
> 其实两阶段提交是经典的分布式系统问题。
>
> Q：能不能不要redolog，只用binlog？
>
> A：不考虑历史原因的话，binlog目前是没有办法支持数据页级的崩溃恢复的。
>
> Q：能不能不要binlog，只用redolog？
>
> A：从崩溃恢复的角度上说是可以的。但是binlog本身有归档和复制的能力。redolog是作为崩溃恢复，是循环写的，所以没办法作为归档。而且公司的很多异构系统都是依赖消费binlog更新自己的数据。

这里验证下两阶段提交模式下，**不同操作阶段mysql宕机后的表现**。

1. 新行写入到内存后宕机，因为没写入redolog，所以写入失败，恢复的时候也不会有这行数据
2. 写入redolog prepare阶段后宕机，还没有刷入binlog，这时候恢复以后发现redolog并没有commit标识，此时根据记录的XA事务找到这个事务，进行回滚。
3. 写入redolog prepare成功，写入binlog后宕机，恢复以后会发现虽然redolog没有commit标识，但是通过XID查询到的binlog已经成功刷入磁盘了，所以MySQL会提交这个事务，并将redolog修改为commit状态。

> Q：redo log是怎么关联到对应的binlog的？
>
> A：redo log和对应的binlog有一个共同的数据字段，叫XID，崩溃恢复的时候，会按顺序扫描redo log。如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。

### Change buffer

Change Buffer是应用在 **非唯一普通索引页** 的缓冲技术。

**Change buffer存在的主要目的是为了减少磁盘随机读，Redolog主要是为了减少磁盘随机写，同时保证crash safe。**

当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在**下次查询需要访问这个数据页**的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作（称为merge操作）。通过这种方式就能保证这个数据逻辑的正确性。

change buffer中不但在内存中有拷贝，也会被写入到磁盘上。change buffer可以看成也是一个数据页，需要被持久化到 系统表空间（ibdata1），以及把这个change buffer页的改动记录在redo log里，事后刷进系统表空间（ibdata1）。

change buffer适用于写多读少的场景，比如账单、日志类等，如果写多读多，会导致不但没有减少随机IO次数，还徒增change log的维护成本。

以 `insert into t(id,k) values(id1,k1),(id2,k2);`这条插入语句为例。因为k2不在内存中，所以用到了change buffer。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/980a2b786f0ea7adabef2e64fb4c4ca3.png)

这条更新语句做了如下的操作（按照图中的数字顺序）：

- Page 1 在内存中，直接更新内存；
- Page 2 没有在内存中，就在内存的 change buffer 区域，记录下“我要往 Page 2 插入一行”这个信息
- 将上述两个动作记入 redo log 中（图中 3 和 4）。

## 三.事务隔离级别

老生常谈的数据库隔离级别规范，如图所示。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/v2-2e1a7203478165890e2d09f36cb39857_1440w.jpg)

Mysql默认的隔离级别是**可重复读**。**一般数据库（如oracle）的可重复读是不能解决幻读问题的，但是Mysql的可重复读其实解决了幻读问题**。https://zhuanlan.zhihu.com/p/117476959

那么，mysql是怎么实现事务隔离的呢？

1. `读未提交`：压根不加锁
2. `串行化`：读的时候加共享锁，也就是其他事务可以并发读，但是不能写。写的时候加排它锁，其他事务不能并发写也不能并发读。

比较复杂的是 `读提交`和 `可重复读`。

### 实现可重复读

为了实现可重复读，MySQL采用了MVCC（多版本并发控制）的方式。

要了解MVCC，我们需要先回顾下前面 **undolog** 这一小节的内容，能明白几个关键点：

- mysql中的每一行数据记录，都会存在事务的id即 `trx_id`，回滚id即 `roll_pointer_id`，而undolog中会记录下数据的每一次变更，通过 `roll_pointer_id`组成一条回滚链。
- 事务id即 `trx_id`在mysql中是根据开启的时间顺序单调递增的，所以按trx_id我们可以看出不同事务的开启时间顺序。

前面我们讲到了，可重复读能够保证某个事务只能看到它开启时已经提交的事务的结果，这个是怎么保证的呢？其实是通过**一致性视图（ReadView）**。

**一致性视图**是InnoDB为每个事务构造的一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务ID。“活跃”指的就是，启动了但还没提交。通过这个数据我们可以判断出来事务执行的先后顺序，事务所能读取的数据版本。

![image-20220415082909691](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/image-20220415082909691.png)

一个数据版本，对于一个事务视图来说，除了自己的更新总是可见以外，有三种情况：

1. 版本未提交，不可见；
2. 版本已提交，但是是在视图创建后提交的，不可见；
3. 版本已提交，而且是在视图创建前提交的，可见。

我们通过一个例子来理解一致性视图是怎么和undolog配合一起来完成可重复读的事务隔离级别的。

![image-20220415083319161](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/image-20220415083319161.png)

假设当前有个正在执行事务99，数据行的历史版本为事务id90（1,1）。

（1）按照事务的开启时间，分别递增分配了100,101,102三个事务ID（trx id）

（2）在SQL语句执行之前，事务A生成一致性视图【99,100】，事务B生成一致性视图【99,100,101】，事务C生成一致性视图【99,100,101,102】

（3）SQL语句的执行之前生成undo log，通过undo log可以生成历史版本数据快照，上图右侧历史版本数据。

（4）事务A的查询执行时，当前数据版本为trx id:101，跟一致性视图【99,100】进行比较，101大于高水位不可见，通过undo log回退到trx id:102版本，102也大于高水位不可见，再回退一个版本到trx id:90，90低于低水位可见，所以事务A读取到的数据为（1.1）。

不知道大家有没有发现一个问题，按照**一致性读**理论，事务B开启的时候，是没有办法看到事务C的数据的，那么事务B的 set k=k+1，为什么会直接在事务C的更新上进行更新呢？这就涉及到**当前读**理论了。

**当前读：更新数据都是先读后写的，而这个读，只能读当前的值，称为当前读。**

因此，在更新的时候，当前读拿到的数据是 (1,2)，更新后生成了新版本的数据 (1,3)，这个新版本的 row trx_id 是 101。在执行事务 B 查询语句的时候，一看自己的版本号是 101，最新数据的版本号也是 101，是自己的更新，可以直接使用，所以查询得到的 k 的值是 3。

事实上，除了update语句外，select语句如果加上锁 `lock in share mode`或 `for update`，也是当前读。

### 实现已提交读

已提交读的特点是，每次读的时候都能读到当前已经提交了的事务的数据。所以它与可重复读的区别是，可重复读是在事务开始的时候去创建一致性视图，而已提交读是每次select的时候都会去重新计算一次一致性视图。

## 四.索引

### 4.1 B+树

索引是由B+树构建而成的，一个索引就是一个B+树。

mysql的页面大小为16k，一个整数（bigint）字段索引的长度为 8B,另外每个索引还跟着6B的指向其子树的指针；所以16K/14B ≈ 1170。即非叶子节点每一页大概有1170个索引项。

假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。索引图如下

![image-20220415092343708](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/image-20220415092343708.png)

根据叶子节点的内容，索引类型分为**主键索引**和**非主键索引**。查询方式也会有所不同。

- 主键索引的叶子节点内容存的是整行数据。也称为聚簇索引。查询的时候，只需要搜索主键索引这棵树，就可以拿到所需要的所有值。
- 非主键索引的叶子节点内容是主键的值，非主键索引也被称为二级索引。查询的时候需要先搜索二级索引的树，拿到对应的主键值即id，然后再通过这个id去主键索引中获取到对应的数据。这过程称为**回表**。

### 4.2 覆盖索引和最左前缀

怎么样可以减少回表次数呢？那就是使用**覆盖索引**。

**覆盖索引**是指通过设计索引的字段，来使得查询的时候可以直接从二级索引中获取需要的字段，而不需要回表。比如执行的语句是 select ID from T where k between 3 and 5，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果

**最左前缀原则**是指当你创建了一个联合索引，该索引的任何最左前缀都可以用于查询。比如当你有一个联合索引 `(col1, col2, col3)`，该索引的所有前缀为 `(col1)`、`(col1, col2)`、`(col1, col2, col3)`，包含这些列的所有查询都会使用该索引进行查询。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/89f74c631110cfbc83298ef27dcd6370.jpg)

然而，联合索引不过是把多个字段按声明顺序放在一起排列起来了，所以如果你的查询有多个条件，比如 姓名第一个字是张并且年龄=10，那么他会先找到ID，然后进行遍历。遍历根据版本不同，会有一些差异。

在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。

而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/76e385f3df5a694cc4238c7b65acfe1b.jpg)

### 4.3 唯一索引和普通索引

普通索引和唯一索引的区别在于：

- 普通索引是将字段放入B+树中进行排序，而唯一索引除了排序之外，还会去校验字段值是否唯一，不能有重复值。
- 从change buffer的角度来看，因为唯一索引必须把该字段下所有的值都读到内存中，所以**唯一索引不能使用change buffer**。而普通索引可以使用。

## 五.锁

根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。

### 5.1 全局锁和表锁

**全局锁**

全局锁就是对对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：数据更新语句（数据的增删改）、数据定义语句（包括建表、修改表结构等）和更新类事务的提交语句。当然，全局锁的操作非常危险，会导致业务停摆。

同时，官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。但是，因为**一致性视图依赖于Innodb引擎**，所以其他引擎无法使用这个功能。

**表级锁**

MySQL 里面表级别的锁有两种：一种是**表锁**，一种是**元数据锁**（meta data lock，MDL)

**表锁**的语法是 lock tables … read/write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。

另一类表级的锁是 **MDL**（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。当对一个表做增删改查操作（DML）的时候，加 MDL 读锁；当要对表做结构变更操作（DDL）的时候，加 MDL 写锁。

- 读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查
- 读写锁之间，写锁之间互斥，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。

因为MDL写锁的时候，会锁住整张表，导致整张表不可读。那么要怎么样去变更一个热点表呢？

比较理想的机制是，在 alter table 语句里面设定等待时间，如果在这个指定的等待时间里面能够拿到 MDL 写锁最好，拿不到也不要阻塞后面的业务语句，先放弃。之后开发人员或者 DBA 再通过重试命令重复这个过程。

### 5.2 行锁

**两阶段锁协议**

在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。

那么知道两阶段锁有什么用呢？就是，**如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放**。


**死锁和死锁检测**

当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/4d0eeec7b136371b79248a0aed005a52.jpg)

死锁以后的解决策略：

- 一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。但是缺点是容易误伤正常等待。
- 另一种策略是，发起**死锁检测**，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 `innodb_deadlock_detect`设置为 on，表示开启这个逻辑。缺点是每个事务被锁之后都要检测，成本较高。

可以使用 show engine innodb status 来查看死锁的原因。



### 5.3 间隙锁

**间隙锁**就是两个值之间的空隙的锁。间隙锁在**可重复读**隔离级别下才生效。

比如有这么六个记录，就会同时加7个间隙锁。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/e7f7ca0d3dab2f48c588d714ee3ac861.png)

间隙锁相互之间不存在冲突关系，间隙锁只跟往间隙中插入记录这个动作有冲突。

**间隙锁**和**行锁**合称 **next-key lock**，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。

通过引入间隙锁和next-key lock，我们解决了幻读的问题，但是也可能会导致“死锁”。就比如下面这个例子，当id=9不存在时，双方都在等待对方释放间隙锁。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/df37bf0bb9f85ea59f0540e24eb6bcbe.png)


一个比较有意思的点是，next-key lock事实上是由右边的记录决定的，是前开后闭的结构。所以间隙可能会在操作中改变：假设有间隙锁 (0, 5)，记录锁 5， 间隙锁(5, 10]，

- 当中间的记录锁5被删除后，会合并为一个大的间隙锁(5, 10]。
- 当记录5被修改为1时，第二个间隙锁(5, 10]会变成(1, 10]。
