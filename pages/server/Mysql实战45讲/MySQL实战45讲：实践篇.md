# MySQL实战45讲：实践篇

这篇文章是MySQL实战45讲中，实践篇这一块的学习记录。

## 普通索引和唯一索引，应该怎么选

唯一索引在更新的时候需要把一个索引下所有的内容都加载到内存中，进行比较后才能确定是否唯一，因此唯一索引没有办法用到change buffer的优化机制，所以相比普通索引，性能会相对差一点。

除非业务确实有唯一的诉求，不然都建议用普通索引。

## MySQL为什么有时候会选错索引

MySQL会在查询优化阶段选择查询所使用的索引，选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。这里提到的最小的代码，是综合多个方面共同来看的：

- 扫描的行数
- 是否使用临时表
- 是否排序
- 是否有回表（未使用覆盖索引）成本
- ...

所以有些时候，即使用一个索引扫描的函数更少，但是结合多种代价综合比较，优化器可能选择一个扫描行数更多的索引。

我们这里单独讨论扫描的行数。可能导致选错索引的原因是**扫描行数判断不准**。

MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的“**区分度**”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“**基数**”（cardinality）。也就是说，**这个基数越大，索引的区分度越好**。

MySQL使用**采样统计**的方法来确定索引的基数。通过默认选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。

由于是采样统计，所以基数很容易不准。当explain预估值和实际值相差较大时可以使用 `analyze table t`命令重新统计索引信息。

## 怎么给字符串字段加索引

当我们需要给一个字符串加索引的时候，如果不指定前缀索引，那么索引字段默认就是全字符串存储，占用的空间会比较大。

但是如果使用了前缀索引，就可能出现**查询语句读数据次数变多**。因为可能相同前缀的字符串需要回表多次。并且由于索引只有一个前缀，也**没办法享受到覆盖索引对于查询性能的优化**。

## 为什么我的mysql会“抖”一下

平时执行很快的更新操作，其实是在写内存和日志，而Mysql偶尔抖一下的那个瞬间，可能是在刷脏页到磁盘上（flush）。

那么，什么情况会引发数据库的 flush 过程呢？

- 第一种场景是，redo log写满了，这时候系统会停止所有更新操作，把checkpoint向前推进，把推进部分的日志涉及到的脏页都flush到磁盘上。这种情况是InnoDB要尽量避免的。
- 第二种场景是，系统内存不足了。这时候就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是脏页，就要先将脏页写到磁盘。这种情况是常态。
- 第三种场景是，系统空闲的时候，当然就算系统负载比较高的时候，也要合理的安排时间，只要有时间就刷一点“脏页”。

InnoDB使用 `innodb_io_capacity`这个参数来设置磁盘能力，建议设置成磁盘的IOPS。这个参数影响挺大的。

InnoDB刷盘的时候也不能全力刷盘，毕竟还要对外提供服务。刷盘速度会参考这两个因素：一个是脏页比例，一个是redo log写盘速度。平时要注意脏页比例。

InnoDB在刷脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个邻居也跟着一起刷掉。InnoDB使用 `innodb_flush_neighbors`参数来控制innodb刷临近脏页的行为，值为0时就是不刷邻居，只刷自己。建议设为0。

## 为什么表数据删掉一半，表文件大小不变

一个InnoDB表包含两部分，即表结构定义和数据，从Mysql 8.0版本以后，表结构定义可以放在系统数据表中了，因为表结构定义占用的空间很小，所以主要是表数据占用空间。

**参数 innodb_file_per_table**

表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：

- 这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；
- 这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。从 MySQL 5.6.6 版本开始，它的默认值就是 ON 了。

这个参数建议设置为on，因为一个表单独存储为一个文件更容易管理，而且在不需要这个表的时候，通过 `drop table`命令，系统就会直接删除这个文件。而如果是放在共享表空间中，即使表删掉了，空间也是不会回收的。

**数据删除流程**

当我们删除记录时，InnoDB会将某条记录标记为删除，如果之后再插入一条记录时，如果位置相同可能会复用这个位置，但是磁盘文件的大小并不会缩小。所以删除数据并不能使整个表空间变小。

但是当我们删除了一个数据页上的所有记录，整个数据页就可以复用了。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另一个数据页就被标记为可复用。

经过大量增删改的表，都是可能存在空洞的，所以如果能把这些空洞去掉，就能达到收缩表空间的目的。而**重建表**就可以去掉。

**重建表**

我们可以使用 `alter table A engine=InnoDB`命令来重建表

Mysql 5.6引入的Online DDL，对重建表的操作流程做了优化。

- 建立一个临时文件，扫描表 A 主键的所有数据页；
- 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
- 生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；
- 临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；
- 用临时文件替换表 A 的数据文件。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/2d1cfbbeb013b851a56390d38b5321f0.png)

由于有日志文件记录和重放操作，这个方案在重建表的过程中，允许对表A做增删改操作，这就是Online DDL名字的由来。

alter语句在启动的时候需要获取MDL写锁，但是这个写锁在真正拷贝数据之前就退化为读锁了。为什么不直接解锁了，主要是避免其他线程同时对这个表做DDL。但是这个获取写锁的时间相当短，对业务来说，可以认为是Online的。一般推荐使用Github开源的gh-ost来做。

> **为什么推荐gh-ost?**
>
> http://mysql.taobao.org/monthly/2018/05/02/  这篇文章比较好的介绍了gh-ost这种基于binlog恢复增量数据和基于触发器的方式的区别。
>
> https://github.com/github/gh-ost/issues/82  这篇文章介绍了gh-ost的新旧表切换cut-over原理。

## Count(*)这么慢，我该怎么办

InnoDB默认的隔离级别是可重复读，在代码上就是通过MVVC并发控制来实现的，**每一行记录都要判断自己是否对这个会话可见，因此对于count(*)请求来说，InnoDB只好把数据一行一行的读出依次判断，可见的行才能够用于计算“基于这个查询”的表的总行数。**

但是数据库本身还是做了一些优化的，因为主键索引数的叶子节点是数据，而普通索引树的叶子结点是主键值。所以，普通索引树比主键索引树小很多。对于count(*)这样的操作，遍历哪棵树得到的结果都是一样的。因此，mysql优化器会找到最小的那棵树来遍历。

如果想优化count的效率，可以把数量放到单独的一张表中，通过事务来读取。如果通过redis来存放的话，可能会有不一致的问题。

**几种count用法的性能差别**

count总共有四种用法：`count(*)、 count(主键 id)、count(字段)、count(1)`。

count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。

对于 `count(主键 id)` 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。

对于 `count(1)` 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。

单看这两个用法的差别的话，你能对比出来，`count(1)` 执行得要比 `count(主键 id)` 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。

对于 `count(字段)` 来说：如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。

但是 `count(*)` 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。`count(*)` 肯定不是 null，按行累加。

所以结论是：按照效率排序的话，count(字段)<count(主键 id)<count(1)≈count(\*)，所以我建议你，尽量使用 count(\*)。

## order by是怎样工作的

Mysql中存在两种排序方式：**全字段排序** 和 **rowid排序**。选择方式主要是看mysql是否认为排序内存足够大。**会优先使用全字段排序，避免二次回表**。

**全字段排序**

全字段排序是将 **通过where语句筛选出来的数据（或者全部数据）** 存放到**sort_buffer**（一块专门用于排序的内存）中，通过 `快速排序算法`来对相应字段进行排序操作。

这里如果sort_buffer存放不下所有的数据，还会借用到磁盘临时文件。通过生成 `number_of_tmp_files`个临时文件，将需要排序的数据分成 12 份，每一份使用快排单独排序后存在这些临时文件中。然后把这 12 个有序文件再通过 `归并排序`合并成一个有序的大文件。

**rowid排序**

如果查询要返回的字段很多，那么sort_buffer中要放的字段数太多，内存中能同时放下的行数较少，要分成很多个临时文件，排序的性能会很差。可以通过 `max_length_for_sort_data`定义单行长度阈值。

这个时候Mysql会采用rowid排序算法，只把主键id和要排序的列放入sort_buffer中。这样的话，执行流程就是：

- 从索引中找到所有符合条件的行；
- 把符合条件的行的id，排序列存入sort_buffer中；
- 对排序列进行排序
- 排序完成后遍历排序结果，取前1000行，并按照id的值回表取出对应的查询列的值。

如果要避免每次都要排序，可以通过建索引的方式来解决，甚至通过覆盖索引优化回表查具体值的操作。

## 为什么有些sql语句逻辑相同，性能却差异巨大

对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。有三个例子：

- 对索引的字段做了函数操作
- 隐式类型转换
- 隐式字符编码转换

## 为什么我只查一行的数据，执行也这么慢

有时候，只查询一行数据，执行也会很慢。以 `select * from t where id=1`为例。

### 查询长时间不返回

1.第一类：等MDL锁

可以使用 `show processlist`命令，看看当前语句处于什么状态

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/5008d7e9e22be88a9c80916df4f4b328.png)

waiting for table metadata lock说明是被MDL写锁住了。

通过查询 `sys.schema_table_lock_waits`这张表，我们就可以直接找出造成阻塞的process id，然后把这个连接用kill命令断开。

2.第二类：等 flush

在表上执行

```mysql
mysql> select * from information_schema.processlist where id=1;
```

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/2d8250398bc7f8f7dce8b6b1923c3724.png)

查出来线程的状态是 waiting for table flush。表示的是，现在有一个线程正要对表 t 做 flush 操作。

MySQL 里面对表做 flush 操作的用法，一般有以下两个：

```mysql
flush tables t with read lock;
flush tables with read lock;
```

这两个 flush 语句，如果指定表 t 的话，代表的是只关闭表 t；如果没有指定具体的表名，则表示关闭 MySQL 里所有打开的表。

但是正常这两个语句执行起来都很快，除非它们也被别的线程堵住了。所以，出现 Waiting for table flush 状态的可能情况是：有一个 flush tables 命令被别的语句堵住了，然后它又堵住了我们的 select 语句。

3.第三类：等行锁

```mysql
mysql> select * from t where id=1 lock in share mode; 
```

由于访问 id=1 这个记录时要加读锁，如果这时候已经有一个事务在这行记录上持有一个写锁，我们的 select 语句就会被堵住。

如果你用的是 MySQL 5.7 版本，可以通过 sys.innodb_lock_waits 表查到谁占着这个写锁。

```mysql
mysql> select * from t sys.innodb_lock_waits where locked_table='`test`.`t`'\G
```

### 查询慢

1.第一类：查询没有走索引

这种情况比较好理解，没有索引的话就是id主键顺序扫描。

2.第二类：undolog过多，查询遍历耗时过长

由于事务中的查询是一致性读，所以查询会遍历undolog，找到自己能看到的事务的写入结果。当undolog过于多时，就会查询耗时长。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/84667a3449dc846e393142600ee7a2ff.png)

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/46bb9f5e27854678bfcaeaf0c3b8a98c.png)

## 幻读是什么，幻读有什么问题

幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。

注意：在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，**幻读在“当前读”下才会出现**。

## 为什么我只改一行的语句，锁这么多？

这篇文章写的非常好，建议看原文：https://time.geekbang.org/column/article/75659

间隙锁加锁规则：

- 原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。

  - 加锁的流程是，先加间隙锁，再加行锁。加间隙锁不会有冲突，**加行锁会有冲突**。
- 原则 2：查找过程中访问到的对象才会加锁。

  - 注意：这个对象指的是列，不是行。加锁的话，是加在索引上的，列上有索引，就加在索引上；列上没有索引就加在主键索引上。
  - lock in share mode与for update的区别：lock in share mode 只锁覆盖索引。执行 for update 时，系统会认为你接下来要更新数据，因此会顺便给主键索引上满足条件的行加上行锁。
  - 在删除数据的时候尽量加limit，这样可以控制数据的条数让操作更安全，还可以减小加锁的范围。
- 优化 1：索引上的等值查询，给唯一索引加锁的时候，也就是等值查询找到了对应的记录，这时候next-key lock 退化为行锁。
- 优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，也就是等值查询没找到对应记录，扫描到了大于目标值的第一条记录时，这时候next-key lock 退化为间隙锁。
- 一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。

换用自己的话总结下：

- 查询过程中访问到的对象才会加锁，而加锁的基本单位是next-key lock（前开后闭）；加锁是加在索引上的，所以对于覆盖索引来说，lock in share mode只会在覆盖索引上加锁，而for update会在主键索引上也一起加上。
- 等值查询上MySQL的优化：索引上的等值查询，如果是唯一索引，next-key lock会退化为行锁，如果不是唯一索引，需要访问到第一个不满足条件的值，此时next-key lock会退化为间隙锁；
- 范围查询：无论是否是唯一索引，范围查询都需要访问到不满足条件的第一个值为止；

## MySQL有哪些“饮鸩止渴”提高性能的方法

业务高峰期，生产环境的 MySQL 压力太大，没法正常响应，需要短期内、临时性地提升一些性能。这时候能有什么方案？有什么问题？

### 短连接风暴

正常的短连接模式就是连接到数据库后，执行很少的 SQL 语句就断开，下次需要的时候再重连。如果使用的是短连接，在业务高峰期的时候，就可能出现连接数突然暴涨的情况。

我们也不能盲目的修改 `max_connections`这个参数，因为这个参数是为了保护Mysql的，改大了系统可能会过载。

这种情况下怎么解决？

**第一种方法：处理掉那些占着连接但是不工作的线程。**

我们可以通过设置 `wait_timeout`来处理空闲连接。设置 `wait_timeout`参数表示的是，一个线程空闲 wait_timeout 这么多秒之后，就会被 MySQL 直接断开连接。

从服务端断开连接使用的是 `kill connection + id`的命令， 一个客户端处于 sleep 状态时，它的连接被服务端主动断开后，这个客户端并不会马上知道。直到客户端在发起下一个请求的时候，才会收到这样的报错“ERROR 2013 (HY000): Lost connection to MySQL server during query”。

**第二种方法：减少连接过程的消耗。**

有的业务代码会在短时间内先大量申请数据库连接做备用，如果现在数据库确认是被连接行为打挂了，那么一种可能的做法，是让数据库跳过权限验证阶段。

跳过权限验证的方法是：重启数据库，并使用 `–skip-grant-tables`参数启动。这样，整个 MySQL 会跳过所有的权限验证阶段，包括连接过程和语句执行过程在内。

但是风险极大，不建议

### 慢查询性能问题

**导致慢查询的第一种可能是，索引没有设计好。**

这种场景一般就是通过紧急创建索引来解决。MySQL 5.6 版本以后，创建索引都支持 Online DDL 了，对于那种高峰期数据库已经被这个语句打挂了的情况，最高效的做法就是直接执行 alter table 语句。

比较理想的是能够在备库先执行。假设你现在的服务是一主一备，主库 A、备库 B，这个方案的大致流程是这样的：

- 在备库 B 上执行 set sql_log_bin=off，也就是不写 binlog，然后执行 alter table 语句加上索引；
- 执行主备切换；这时候主库是 B，备库是 A。
- 在 A 上执行 set sql_log_bin=off，然后执行 alter table 语句加上索引。

**导致慢查询的第二种可能是，语句没写好。**

MySQL 5.7 提供了 query_rewrite 功能，可以把输入的一种语句改写成另外一种模式。

比如，语句被错误地写成了 select * from t where id + 1 = 10000，你可以通过下面的方式，增加一个语句改写规则。

```mysql
mysql> insert into query_rewrite.rewrite_rules(pattern, replacement, pattern_database) values ("select * from t where id + 1 = ?", "select * from t where id = ? - 1", "db1");
call query_rewrite.flush_rewrite_rules();
```

**导致慢查询的第三种可能，就是选错了索引。**

这时候，应急方案就是给这个语句加上 force index。同样地，使用查询重写功能，给原来的语句加上 force index，也可以解决这个问题。

## mysql是怎么保证数据不丢的

前面讲到了，只要redo log和binlog保证持久化到磁盘，就能确保mysql异常重启后，数据可以恢复。

### binlog写入机制

事务执行过程中，先把日志写到 binlog cache，事务提交的时候，再把 binlog cache 写到 binlog 文件中，然后清空binlog cache。

系统给 binlog cache 分配了一片内存，每个线程一个，参数 `binlog_cache_size `用于控制单个线程内 binlog cache 所占内存的大小。如果超过了这个参数规定的大小，就要暂存到磁盘。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/9ed86644d5f39efb0efec595abb92e3e.png)

图中的 **write**，指的就是指把日志写入到文件系统的 page cache，并没有把数据持久化到磁盘，所以速度比较快。

图中的 **fsync**，才是将数据持久化到磁盘的操作。一般情况下，我们认为 fsync 才占磁盘的 IOPS。

write 和 fsync 的时机，是由参数 sync_binlog 控制的：

- sync_binlog=0 的时候，表示每次提交事务都只 write，不 fsync；
- sync_binlog=1 的时候，表示每次提交事务都会执行 fsync；
- sync_binlog=N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。

sync_binlog=N时，IO性能较好，但是异常重启会丢失最近N个事务的binlog日志。一般建议设置为1

### redolog 写入机制

redolog与binlog类似，也是 redolog buffer-> page cache -> disk 三种状态。

对于每一个事务来说，InnoDB 提供了 `innodb_flush_log_at_trx_commit`参数，它有三种可能取值：

- 设置为 0 的时候，表示每次事务提交时都只是把 redo log 留在 redo log buffer 中;
- 设置为 1 的时候，表示每次事务提交时都将 redo log 直接持久化到磁盘；
- 设置为 2 的时候，表示每次事务提交时都只是把 redo log 写到 page cache。

对于全局来说，InnoDB 有一个后台线程，每隔 1 秒，就会把 redo log buffer 中的日志，调用 write 写到文件系统的 page cache，然后调用 fsync 持久化到磁盘。

如果把 `innodb_flush_log_at_trx_commit` 设置成 1，那么 redo log 在 prepare 阶段就要持久化一次，因为有一个崩溃恢复逻辑是要依赖于 prepare 的 redo log，再加上 binlog 来恢复的。每秒一次后台轮询刷盘，再加上崩溃恢复这个逻辑，InnoDB 就认为 redo log 在 commit 的时候就不需要 fsync 了，只会 write 到文件系统的 page cache 中就够了。--- **所以只在prepare刷盘，commit不刷盘**。

为了提高redolog刷盘的效率，mysql用到了**组提交机制**。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/933fdc052c6339de2aa3bf3f65b188cc.png)

当多个事务在一个时间段里都要刷盘的时候，会一次性刷了这几个。可以通过参数配置组提交的效果。两者是或的关系。

- `binlog_group_commit_sync_delay` 参数，表示延迟多少微秒后才调用 fsync
- `binlog_group_commit_sync_no_delay_count` 参数，表示累积多少次以后才调用 fsync。

## Mysql是怎么保证主备一致的

### binlog同步流程

下图是基本的主备切换流程，当出现问题时，mysql可以从状态1切换到状态2，把mysql B作为主库。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/fd75a2b37ae6ca709b7f16fe060c2c10.png)

我们先来看状态1中，mysql A的数据是怎么同步到Mysql B的。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/a66c154c1bc51e071dd2cc8c1d6ca6a3.png)

主库A中有一个dump_thread线程，专门服务于从库。从库的IO线程会请求主库的binlog，并将得到的binlog写到本地的 `relay log文件`中，从库的sql线程会读取relay log文件中的日志，并解析成sql语句进行执行。

### binlog的三种格式

binlog有三种格式：

- statement：即实际执行的指令。但是会出现主备数据不一致的情况，因为有些语句，主备执行可能不一样。
- row：对应行的变更。缺点是很占空间，一行指令可能产生成千上万条row日志。
- mix：statement和row的折中方案，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。

越来越多场景会使用row这种格式，有这么几个优点：

- 便于**恢复数据**。
- 便于**备库消费**：备库消费binlog时，如果两个事务没有更新相同的行，那就可以并行执行。是否相同依赖row格式。

### 循环复制问题

上面的图是M-S结构，但事实上通常Mysql A和Mysql B会是双M结构。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/20ad4e163115198dc6cf372d5116c956.png)

业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（这里可以把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是**循环复制**了。这个要怎么解决呢？

解决方法是：

- 两个库拥有不同的server id。在主库第一次生成server id时，用的是主库的server id。
- 备库在重放binlog的时候，生成与原binlog的server id相同的新binlog
- 每个库在收到从自己的主库发过来的日志后，判断server id，如果与自己一致，则放弃重放。

## Mysql是怎么保证高可用的

### 主备延迟

主备之间同步有这么几个节点：

- 主库A完成事务，写入binlog，记为T1；
- 备库B接收到主库A传送过来的日志，记为T2；
- 备库B执行完成这个事务，记为T3；

**主备延迟** 通常指的是T1到T3的间隔时间。我们可以用 `show slave status `来查看备库延迟了多少秒 `seconds_behind_master`。

在网络正常的时候，日志从主库传给备库所需的时间是很短的。也就是说，网络正常情况下，主备延迟的主要来源是备库接收完 binlog 和执行完这个事务之间的时间差。也就是**备库消费中转日志（relay log）的速度，比主库生产 binlog 的速度要慢**。

**主备延迟的可能原因**：

| 原因                                               | 解决办法         |
| -------------------------------------------------- | ---------------- |
| 备库所在机器的性能要比主库所在的机器性能差         | 对称部署         |
| 备库压力大。比如读压力过高，某个查询语句性能较差等 | 一主多从分散压力 |
| 大事务，如批量删除，大表DDL                        | 使用gh-ost       |
| 备库的并行复制能力                                 |                  |

由于主备延迟的存在，在主备切换的时候，也有不同的策略。我们一般使用**可靠性优先策略**。

1.可靠性优先策略

- 判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；
- 把主库 A 改成只读状态，即把 readonly 设置为 true；
- 判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；
- 把备库 B 改成可读写状态，也就是把 readonly 设置为 false；
- 把业务请求切到备库 B。

这个策略可以保证数据准确性，但是中间会有一段时间双库都是readonly状态，无法对外提供服务。

2.可用性优先策略

可用性优先即将可靠性优先策略的第四、第五步放到前面来执行，也就是先将B设置为主库，这样就会出现双主库的情况，出现脑裂问题。

## 备库为什么会延迟好几个小时

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/1a85a3bac30a32438bfd8862e5a34eef-20220529123115187.png)

从这张主备流程图的两个黑色箭头来看，由于InnoDB支持行级锁，所以并发能力很强，而日志在备库上的执行，如果是单线程的话，就会导致备库应用日志不够快，造成主备延迟。

常用的解决方案就是，在备库消费事务的时候，添加多线程支持。但是多线程应用就会带来一个问题：事务是否能完全不考虑顺序，并行在不同线程上应用？另一个问题是，同一个事务的多个更新语句，能不能分给不同的线程来执行呢？

答案都是不能的，因为事务在主库上运行的时候是有序的，如果在备库上应用无脑使用多线程，就会导致本来在后面的事务反而跑到前面去运行了。并且同一个事务的不同更新语句也是有顺序依赖的，不能分给不同线程执行。

因此，binlog在备库上进行分发的时候，需要满足两个基本要求：

1. 不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。
2. 同一个事务不能被拆开，必须放到同一个 worker 中。

在这两个前提下，会有三种更新策略：

- 按表分发：每个线程中维护一份当前正在应用的数据表的hash表，如果有新的事务过来了，判断这个事务修改到了哪些表，跟哪些线程中正在运行的事务有冲突。如果跟多于一个线程有冲突，则进行等待；如果只跟一个线程有冲突，则分发给这个线程；如果不冲突，则可找个负载低的线程执行。缺点是当热点表更新频繁时，备库会退化为单线程
- 按行分发：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。缺点是计算很耗费CPU和内存
- **模拟主库并行模式**：这个最初是MariaDB提出来的，它利用的是redo log组提交的特性：
  - 能在同一组里提交的事务，一定不会修改同一行
  - 主库上可以并行执行的事务，备库上也可以并行执行

其中，模拟主库并行模式这个策略，MariaDB是以Commit作为一个节点，只有同时处于commit状态的事务才可以并行。但是事实上，只要能同时进入到prepare状态的事务，都是经过了事务的并发性校测的，都可以并行。

![img](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/5ae7d074c34bc5bd55c82781de670c28-20220529125955925.png)

因此，MySQL 5.7 并行复制策略的思想是：同时处于 prepare 状态的事务，在备库执行时是可以并行的；处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。

**MySQL 5.7.22 的并行复制策略**

Mysql 5.7.22在MariaDB思想的基础上，增加了新的策略，基于WRITESET的并行复制

新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。

- COMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。
- WRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。
- WRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。

## 读写分离有哪些坑

读写分离指的是主库负责写入和部分读，从库来分担读压力。但是这样就会带来一个问题，因为主从延迟是不可避免的，所以从库去读的时候，就可能读到旧值，称为**过期读**。

解决过期读的方案：

- 强制走主库方案；
  - 对于必须要拿到最新结果的请求，强制将其发到主库上。
- sleep 方案；
  - 主库更新后，读从库之前先sleep一下，类似于执行一条select sleep(1)命令。这个方案的假设是，大多数情况下主备延迟在一秒以内。但是这个方案用户体验不好。
- 判断主备无延迟方案；
  - 通过 `show slave status`结果中的 `seconds_behind_master`参数的值，来衡量主备延迟时间的长短。
  - 
- 配合 semi-sync 方案；
- 等主库位点方案；
- 等 GTID 方案。

## 为什么有kill不掉的语句

在 MySQL 中有两个 kill 命令：一个是 kill query + 线程 id，表示终止这个线程中正在执行的语句；一个是 kill connection + 线程 id，这里 connection 可缺省，表示断开这个线程的连接，当然如果这个线程有语句正在执行，也是要先停止正在执行的语句的。

当用户执行 kill query thread_id_B 时，MySQL 里处理 kill 命令的线程做了两件事：

- 把 session B 的运行状态改成 THD::KILL_QUERY(将变量 killed 赋值为 THD::KILL_QUERY)；
- 给 session B 的执行线程发一个信号。

为什么要发信号呢？因为像图 1 的我们例子里面，session B 处于锁等待状态，如果只是把 session B 的线程状态设置 THD::KILL_QUERY，线程 B 并不知道这个状态变化，还是会继续等待。发一个信号的目的，就是让 session B 退出等待，来处理这个 THD::KILL_QUERY 状态。

**为什么kill不掉呢？**

因为发送 kill 命令的客户端，并没有强行停止目标线程的执行，而只是设置了个状态，并唤醒对应的线程。而被 kill 的线程，需要执行到判断状态的“埋点”，才会开始进入终止逻辑阶段。并且，终止逻辑本身也是需要耗费时间的。比较常见的耗时场景有：

1. 超大事务执行期间被 kill。这时候，回滚操作需要对事务执行期间生成的所有新数据版本做回收操作，耗时很长。
2. 大查询回滚。如果查询过程中生成了比较大的临时文件，加上此时文件系统压力大，删除临时文件可能需要等待 IO 资源，导致耗时较长。
3. DDL 命令执行到最后阶段，如果被 kill，需要删除中间过程的临时文件，也可能受 IO 资源影响耗时较久。

## 我查这么多数据，会不会把数据库内存打爆？

考虑一个问题，我的主机内存只有 100G，现在要对一个 200G 的大表做全表扫描，会不会把数据库主机的内存用光了？

其实不会，因为mysql不会保存完整的数据集。server层取数据和发数据的流程是这样的：

- 获取一行，写到 net_buffer 中。这块内存的大小是由参数 net_buffer_length 定义的，默认是 16k。
- 重复获取行，直到 net_buffer 写满，调用网络接口发出去。
- 如果发送成功，就清空 net_buffer，然后继续取下一行，并写入 net_buffer。
- 如果发送函数返回 EAGAIN 或 WSAEWOULDBLOCK，就表示本地网络栈（socket send buffer）写满了，进入等待。直到网络栈重新可写，再继续发送。

流程如下：

![](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/20220724162605.png)

而对于engine层来看，如果涉及到大数据的全局扫描，那就可能会出现磁盘的冷数据页被刷新到内存buffer_pool中，导致线上请求内存命中率暴跌。innodb为了解决这个问题，设计了基于young-old 分区lru淘汰算法。

![](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/20220724164554.png)

在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5/8 处。也就是说，靠近链表头部的 5/8 是 young 区域，靠近链表尾部的 3/8 是 old 区域。

改进后的 LRU 算法执行流程变成了下面这样。

- 图 7 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。
- 之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。
- 处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。

因此，冷数据刷入内存导致的影响就降低了。



## 自增主键为什么不是连续的

自增主键修改的时机，是在真正执行插入数据的操作之前。所以当自增步长为1时，也存在多种可能导致自增主键非连续：

1. 唯一键冲突
2. 事务回滚
3. 批量插入数据的语句，mysql有一个批量申请自增id的策略。同一个语句去申请自增 id，每次申请到的自增 id 个数都是上一次的两倍。这样就可能导致有很多id没有用上。
