# 消息队列高手课

> 这篇文章是我学习极客时间《消息队列高手课》的笔记。

### 一.该如何选择消息队列

作为一款及格的消息队列产品，必须具备的几个特性包括：

- 消息的可靠传递：确保不丢消息；
- Cluster：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息；
- 性能：具备足够好的性能，能满足绝大多数场景的性能要求。

可供选择的消息队列产品有

1. RabbitMQ
   - 优点是有一个很有特色的Exchange交换机模块，可以根据配置的路由规则将生产者发出的消息分发到不同的队列中。
   - 缺点是对消息堆积的支持不好，当大量消息堆积的时候，性能会急剧下降；性能最差
2. RocketMQ
   - 优点是有不错的性能，稳定性和可靠性，社区活跃；适用于在线业务
   - 缺点是生态系统集成和兼容程度稍逊一筹
3. Kafka
   - Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域，几乎所有的相关开源软件系统都会优先支持 Kafka。
   - 使用了大量的批量和异步的思想，所以性能很高，但是也导致同步收发消息的响应时延比较高
   - 适用于离线场景



### 二.发布-订阅模型

Kafka和RocketMQ都是用的相同的消息模型。

![img](https://static001.geekbang.org/resource/image/d5/54/d5c0742113b2a6f5a419e1ffc3327354.jpg)

而为了支持并发生产和消费，在主题里面新增了队列的概念。主题和队列的关系是：

- 一个主题可以拥有多个队列，生产者在向主题生产消息的时候，一条消息可能会进入任意一个队列，这样当拥有多个队列的时候，生产者就可以以并发生产的方式加大生产速度。
- 而消费的时候，采用了消费组的概念。消费组彼此之间互不影响。topic中的每个队列都会记录每个消费组在这个队列上的消费位置，这样每个消费组都能消费完topic里面所有队列的消息。
- 消费组里可以有多个消费者，这些消费者对于同一个主题是竞争关系。这样就可以并行的消费了。

![img](https://static001.geekbang.org/resource/image/46/17/465142ab5b5096f283118c307e8cc117.jpg)

这里的队列，在rocketmq中对应MessageQueue，在kafka中对应Partition。



### 三.事务消息

消息重试机制：若Consumer消费某条消息失败，则消息队列RocketMQ版会在重试间隔时间后，将消息重新投递给Consumer消费，若达到最大重试次数后消息还没有成功被消费，则消息将被投递至[死信队列](https://help.aliyun.com/document_detail/87277.htm#concept-2047154)

在某些场景下，我们需要**发消息**及**需要执行的操作**达到**同时成功，或者同时失败**的情况，这种情况下就需要使用**事务消息**。一个典型的使用场景是创建订单后，发消息清除购物车中的商品。这个场景的每一步都可能会失败。

- 如果先发消息，创建订单可能失败，但是商品已经被删除了
- 如果先创建订单，则发消息可能失败，导致无法删除商品

在这种情况下，可以使用事务消息。先发送一条half消息，然后创建订单，再根据订单创建的结果进行提交事务消息或者回滚。

![img](https://static001.geekbang.org/resource/image/11/7a/11ea249b164b893fb9c36e86ae32577a.jpg)

当第四步，提交事务消息和回滚失败后，kafka会直接失败，而rocketmq会定时进行事务反查，需要业务方提供反查接口，查询第二步是否执行成功，然后在判断是提交还是回滚。



### 四.如何确保消息不丢失

一条消息从生产到消费完成的过程，可以分为三个阶段。

![img](https://static001.geekbang.org/resource/image/81/05/81a01f5218614efea2838b0808709205.jpg)

- 生产阶段: 在这个阶段，从消息在 Producer 创建出来，经过网络传输发送到 Broker 端。
- 存储阶段: 在这个阶段，消息在 Broker 端存储，如果是集群，消息会在这个阶段被复制到其他的副本上。
- 消费阶段: 在这个阶段，Consumer 从 Broker 上拉取消息，经过网络传输发送到 Consumer 上。

生产阶段消息队列采用最常用的请求确认机制，来保证消息的可靠传递。客户端把消息发送到Broker，Broker受到消息后，给客户端一个确认响应。

存储阶段，可能出现问题的原因是Broker出现故障。这种情况下，可以通过配置Broker参数来避免宕机丢消息。如果是单机模式Broker，可以配置刷盘方式flushDiskType配置为SYNC_FLUSH同步刷盘，将消息写入磁盘后再给Producer返回确认响应。如果Broker是多个节点组成的集群，拥有多个master和slave，那么则至少需要写入两个主节点成功以后才返回确认响应。

消费阶段采用了和生产阶段类似的确认机制来保证消息的可靠传递。



### 五.如何处理消费过程中的重复消息

消息重复的情况必然存在。在 MQTT 协议中，给出了三种传递消息时能够提供的服务质量标准，这三种服务质量从低到高依次是：

- At most once: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。
- At least once: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。
- Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。

我们现在使用的绝大部分消息队列提供的服务质量都是at least once。

解决重复消息的方法是，在消费端，让我们消费消息的操作具有**幂等性**。有几种常用的设计幂等操作的方法：

1. 利用**数据库的唯一约束**实现幂等。比如mysql的insert if not exist，或者redis的setnx命令。
2. 为更新的数据**设置一个前置条件**，如果满足条件就更新数据。比如给数据增加一个版本号属性，每次更新数据前，比较当前数据的版本号是否和消息中的版本号一致，不一致就拒绝更新。更新数据的同时将版本号+1
3. 通用性最强的幂等方法：**记录并检查操作**。在执行数据更新操作之前，先检查一下是否执行过这个更新操作。比如给每条消息指定一个全局唯一的ID，消费时根据id检查是否有被消费过。



### 六.Kafka是如何提升性能的

kafka广泛用于离线数据流场景，性能非常好。主要是因为他做了这样的一些设计。

1.**使用批量消息提升服务端处理能力**。

发送端只提供了一个send()方法，其实默认是将发送的消息先放在内存中缓存起来，然后选择合适时机将缓存中的消息组成一批，一次性发给broker。broker在接收到这些消息后，不是拆分成一条一条的消息，而是直接批量处理，把一批消息当做一个“批消息”来处理。而消费的时候，同样也是consumer从broker拉到一批消息后，在客户端把批消息解开，再一条一条交给用户代码处理。

2.**使用顺序读写提升磁盘IO性能**

对于磁盘来说，顺序读写比随机读写省去了大部分的寻址时间，只需要寻址一次，就可以连续的读写下去，所以性能好很多。Kafka 就是充分利用了磁盘的这个特性。它的存储设计非常简单，对于每个分区，它把从 Producer 收到的消息，顺序地写入对应的 log 文件中，一个文件写满了，就开启一个新的文件这样顺序写下去。消费的时候，也是从某个全局的位置开始，也就是某一个 log 文件中的某个位置开始，顺序地把消息读出来。

3.**利用page cache加速消息读写**

[基于SSD的Kafka应用层缓存架构设计与实现](https://cloud.tencent.com/developer/article/1778812)这篇文章讲得很好。

![](https://cdn.jsdelivr.net/gh/oubindo/ImageBed@latest//img/20220115150604.png)

对于Produce请求：Server端的I/O线程统一将请求中的数据写入到操作系统的PageCache后立即返回，当消息条数到达一定阈值后，Kafka应用本身或操作系统内核会触发强制刷盘操作（如左侧流程图所示）。

对于Consume请求：主要利用了操作系统的ZeroCopy机制，当Kafka Broker接收到读数据请求时，会向操作系统发送sendfile系统调用，操作系统接收后，首先试图从PageCache中获取数据（如中间流程图所示）；如果数据不存在，会触发缺页异常中断将数据从磁盘读入到临时缓冲区中（如右侧流程图所示），随后通过DMA操作直接将数据拷贝到网卡缓冲区中等待后续的TCP传输。

综上所述，Kafka对于单一读写请求均拥有很好的吞吐和延迟。处理写请求时，数据写入PageCache后立即返回，数据通过异步方式批量刷入磁盘，既保证了多数写请求都能有较低的延迟，同时批量顺序刷盘对磁盘更加友好。处理读请求时，实时消费的作业可以直接从PageCache读取到数据，请求延迟较小，同时ZeroCopy机制能够减少数据传输过程中用户态与内核态的切换，大幅提升了数据传输的效率。



### 七.kafka和rmq消息复制的区别

**rmq：Broker为复制单位**

在2018年前，rmq是采用主从异步复制，采用多主从模式进行灾备，一个主挂了，就切换到另一个。但是这种多主从模式没办法同时解决严格顺序和可用性的问题。

在2018年底，rmq迎来了重大更新。他引入了Deldger，修改了复制方式。

- 首先，Dledger 在写入消息的时候，要求至少消息复制到半数以上的节点之后，才给客户端返回写入成功，并且它是支持通过选举来动态切换主节点的。
- 当主节点宕机的时候，2 个从节点会通过投票选出一个新的主节点来继续提供服务，相比主从的复制模式，解决了可用性的问题。由于消息要至少复制到 2 个节点上才会返回写入成功，即使主节点宕机了，也至少有一个节点上的消息是和主节点一样的。Dledger 在选举时，总会把数据和主节点一样的从节点选为新的主节点，这样就保证了数据的一致性，既不会丢消息，还可以保证严格顺序。

缺点是因为deldger复制方式，至少需要三个节点才能满足可用性要求。所以资源利用率会较低。



**kafka：以分区为复制单位**

Kafka 中，复制的基本单位是分区。每个分区的几个副本之间，构成一个小的复制集群，Broker 只是这些分区副本的容器，所以 Kafka 的 Broker 是不分主从的。

分区的多个副本中也是采用一主多从的方式。Kafka 在写入消息的时候，采用的也是异步复制的方式。消息在写入到主节点之后，并不会马上返回写入成功，而是等待足够多的节点都复制成功后再返回。这个写入节点数，交给用户配置。

Kafka 使用 ZooKeeper 来监控每个分区的多个节点，如果发现某个分区的主节点宕机了，Kafka 会利用 ZooKeeper 来选出一个新的主节点，这样解决了可用性的问题。

但是kafka没办法完全解决顺序消息的问题：

1.分区变更。假设有集群中有两个分区的主题 A，生产端需要往分区 1 发送 3 条顺序消息，我们都知道生产端是根据消息 Key 取模计算决定消息发往哪个分区的，如果此时生产端发送第三条消息前，主题 A 增加了一个分区，生产端根据 Key 取模得出的分区号就不一样了，第三条消息路由到其它分区，结果就是这三条顺序消息就不在同一个分区了，此时就不能保证这三条消息的消费顺序了。

2.分区不变更

- 分区单副本：这种单副本情况下，当这个分区所在的broker宕机了，这个分区就不再可用，生产端就会路由消息到别的分区。
- 分区多副本：开启分区多副本，并且发送端必须消息同步到全部副本后才返回发送成功。可以解决上面分区单副本的问题。但是当主分区挂了，进行重新选举的时候，也会出现消息被路由到其他分区的可能。



### 八.kafka多消费者模型

kafka 的消费类 KafkaConsumer 是非线程安全的，因此用户无法在多线程中共享一个 KafkaConsumer 实例，且 KafkaConsumer 本身并没有实现多线程消费逻辑，如需多线程消费，还需要用户自行实现，在这里我会讲到 Kafka 两种多线程消费模型。

1、每个线程维护一个 KafkaConsumer

这样相当于一个进程内拥有多个消费者，也可以说消费组内成员是有多个线程内的 KafkaConsumer 组成的。

![img](https://gitee.com/objcoding/md-picture/raw/master/img/20200426193745.png)

但其实这个消费模型是存在很大问题的，从消费消费模型可看出每个 KafkaConsumer 会负责固定的分区，因此无法提升单个分区的消费能力，如果一个主题分区数量很多，只能通过增加 KafkaConsumer 实例提高消费能力，这样一来线程数量过多，导致项目 Socket 连接开销巨大，项目中一般不用该线程模型去消费。

2、单 KafkaConsumer 实例 + 多 worker 线程

针对第一个线程模型的缺点，我们可采取 KafkaConsumer 实例与消息消费逻辑解耦，把消息消费逻辑放入单独的线程中去处理，线程模型如下：

![img](https://gitee.com/objcoding/md-picture/raw/master/img/20200426195213.png)

从消费线程模型可看出，当 KafkaConsumer 实例与消息消费逻辑解耦后，我们不需要创建多个 KafkaConsumer 实例就可进行多线程消费，还可根据消费的负载情况动态调整 worker 线程，具有很强的独立扩展性，在公司内部使用的多线程消费模型就是用的单 KafkaConsumer 实例 + 多 worker 线程模型。

但这个消费模型由于消费逻辑是利用多线程进行消费的，因此并不能保证其消息的消费顺序，在这里我们可以引入阻塞队列的模型，一个 woker 线程对应一个阻塞队列，线程不断轮训从阻塞队列中获取消息进行消费，对具有相同 key 的消息进行取模，并放入相同的队列中，实现顺序消费， 消费模型如下：

![img](https://gitee.com/objcoding/md-picture/raw/master/img/20200426210045.png)

在这种模式下，可能因为消费者rebalance导致消费者当前消费的分区别分配给其他消费组，但是消费者本地拉取回来的消息还没有被消费，导致消费顺序错乱。**除非在消费过程中锁定分区，不分配给别的消费者**。

上面这种模式，rocketmq已经原生支持，实现也类似。

















